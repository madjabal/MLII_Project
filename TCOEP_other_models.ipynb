{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('raw_data_bbg.xlsx',\n",
    "                 sheet_name='px_data',\n",
    "                header=0)\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "# Because of saving issues, 39 NA appeared at the tail\n",
    "df = df.iloc[:-39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "px=df.dropna(axis=1) #drop stocks without full data, 88 stocks remain\n",
    "px=px.set_index('Date')\n",
    "#px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL UW Equity', 'ABT UN Equity', 'ACN UN Equity', 'ADBE UW Equity',\n",
       "       'AIG UN Equity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list=px.columns\n",
    "stock_list[:5] #show first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stock_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be part of the feature space\n",
    "ma11=px.rolling(11).mean() \n",
    "ma50=px.rolling(50).mean()\n",
    "ma200=px.rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_excel('raw_data_bbg.xlsx',sheet_name='earn_data',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "earn_dates=df2.iloc[:, range(2,807,8) ]\n",
    "earn_dates.columns=df.columns[1:]\n",
    "#earn_dates  #holds the earnings announcement dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS=df2.iloc[:, range(5,807,8) ]\n",
    "EPS.columns=df.columns[1:]\n",
    "#EPS   #holds the 'comparable' EPS, i.e. not basic EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_EPS=df2.iloc[:, range(6,807,8) ]\n",
    "est_EPS.columns=df.columns[1:]\n",
    "#est_EPS   #holds the forecast consensus for the comparable EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of CorrelNowcast algorithm from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_CorrelNowcast(s, W, model, X_all, y_all, Info, start_date, end_date): \n",
    "    # s for bbg ticker, W for window size, nu for regularization param\n",
    "    # output inclusive of end date\n",
    "    \n",
    "    begin = np.where(X_all.index==start_date)[0][0] #get integer index corresponding to date\n",
    "    end = np.where(X_all.index==end_date)[0][0] \n",
    "\n",
    "    Ew_X = X_all.iloc[begin-W:begin,:] \n",
    "    Ew_y = y_all.iloc[begin-W:begin,0].to_numpy() #0 for the EPS column\n",
    "\n",
    "    model.fit(Ew_X, Ew_y) #initialize\n",
    "\n",
    "    P = None\n",
    "    Q = None\n",
    "    output = np.zeros(end-begin+1)\n",
    "    for t in range(begin, end+1):\n",
    "\n",
    "        P = pd.DataFrame([X_all.iloc[t,:].to_numpy()]) \\\n",
    "            if P is None else P.append(pd.DataFrame([X_all.iloc[t,:].to_numpy()]))\n",
    "\n",
    "        if Q is None:\n",
    "            Q = list(model.predict(X_all.iloc[t,:].to_numpy().reshape(1,-1)))\n",
    "        else:\n",
    "            Q.append(model.predict(X_all.iloc[t,:].to_numpy().reshape(1,-1)))\n",
    "        \n",
    "        output[t-begin] = np.mean(Q)\n",
    "\n",
    "        if X_all.index[t] in Info.index: #if we are at an earnings announcement date\n",
    "            P.columns=Ew_X.columns #needed for correct appending\n",
    "            Ew_X=Ew_X.append(P) #works as the for loop in the paper\n",
    "            Ew_y=np.concatenate([Ew_y, [Info.loc[X_all.index[t], 'EPS']]*len(Q)])\n",
    "            P=None\n",
    "            Q=None\n",
    "            \n",
    "            if Ew_X.shape[0]>W:\n",
    "                Ew_X=Ew_X.iloc[-W:,:] #keep only W rows\n",
    "                Ew_y=Ew_y[-W:]\n",
    "            \n",
    "            model.fit(Ew_X, Ew_y) #retrain\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation for nu and W (this code takes 6 hrs to run, results saved as text below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in loop: nu=10, W=11...0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687\n",
      "CPU times: user 55min 24s, sys: 161 ms, total: 55min 24s\n",
      "Wall time: 55min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{11: 0.21839646295076245}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "nu=np.array([10, 100, 1000, 3000, 5000, 10000])\n",
    "W=np.array([11, 50, 125, 200, 250, 350]) #not doing 500 and 700\n",
    "\n",
    "W = [11]\n",
    "\n",
    "cv_result=dict()\n",
    "\n",
    "model = LassoCV()\n",
    "\n",
    "for b in W:\n",
    "    print('Now in loop: nu={:d}, W={:d}...'.format(a,b), end='')\n",
    "    MRE = np.zeros(len(stock_list))\n",
    "    for i, ticker in enumerate(stock_list):\n",
    "        start = time()\n",
    "        print(i, end='') #visualize progress\n",
    "        cor11=px[ticker].rolling(11).corr(px)\n",
    "        cor50=px[ticker].rolling(50).corr(px)\n",
    "        cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "\n",
    "        temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "        temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "        X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True, suffixes=['_50', '_200'])\n",
    "        X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "        Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                              'EPS':EPS[ticker].dropna(),\n",
    "                              'est_EPS':est_EPS[ticker].dropna()})\n",
    "        Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "        #X and y_extra_info shall hv same no. of rows\n",
    "        y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "        y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                            #remaining at the end since earnings not out yet. We\n",
    "                                            #won't be using those rows\n",
    "\n",
    "\n",
    "        #cross validation period\n",
    "        start_date = '2013-02-08'\n",
    "        end_date = '2015-02-09'\n",
    "\n",
    "        params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "        y_pred = my_CorrelNowcast(**params)\n",
    "\n",
    "        MRE[i] = mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "\n",
    "    cv_result[b]=np.mean(MRE)\n",
    "\n",
    "    print('')   \n",
    "            \n",
    "\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " cv_result saved as text here:{(10, 11): 0.2187638191270434,\n",
    " (10, 50): 0.22906451942601178,\n",
    " (10, 125): 0.31202466937432827,\n",
    " (10, 200): 0.3825881964232682,\n",
    " (10, 250): 0.33047717422058687,\n",
    " (10, 350): 0.3705547594743095,\n",
    " (100, 11): 0.21851150849725237,\n",
    " (100, 50): 0.22558408007391287,\n",
    " (100, 125): 0.26659903572682564,\n",
    " (100, 200): 0.2640797603053457,\n",
    " (100, 250): 0.2703969553958662,\n",
    " (100, 350): 0.29776815242467924,\n",
    " (1000, 11): 0.21763164046085368,\n",
    " (1000, 50): 0.22069437118027563,\n",
    " (1000, 125): 0.23746854866082315,\n",
    " (1000, 200): 0.22573256964428604,\n",
    " (1000, 250): 0.23435294423273242,\n",
    " (1000, 350): 0.25400878483123424,\n",
    " (3000, 11): 0.21708701575300682,\n",
    " (3000, 50): 0.21948953352799538,\n",
    " (3000, 125): 0.22872920667907815,\n",
    " (3000, 200): 0.2225562088940296,\n",
    " (3000, 250): 0.2264492982777717,\n",
    " (3000, 350): 0.24119754914558456,\n",
    " (5000, 11): 0.21686743840521164,\n",
    " (5000, 50): 0.21898640741750486,\n",
    " (5000, 125): 0.22568012060609888,\n",
    " (5000, 200): 0.22240374315178094,\n",
    " (5000, 250): 0.2248758424106235,\n",
    " (5000, 350): 0.23697964201516844,\n",
    " (10000, 11): 0.21669252019829163,\n",
    " (10000, 50): 0.21852854901945928,\n",
    " (10000, 125): 0.2232050513633187,\n",
    " (10000, 200): 0.22266263741956352,\n",
    " (10000, 250): 0.2246121264495324,\n",
    " (10000, 350): 0.2330335124678897}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_text = {(10, 11): 0.2187638191270434,\n",
    " (10, 50): 0.22906451942601178,\n",
    " (10, 125): 0.31202466937432827,\n",
    " (10, 200): 0.3825881964232682,\n",
    " (10, 250): 0.33047717422058687,\n",
    " (10, 350): 0.3705547594743095,\n",
    " (100, 11): 0.21851150849725237,\n",
    " (100, 50): 0.22558408007391287,\n",
    " (100, 125): 0.26659903572682564,\n",
    " (100, 200): 0.2640797603053457,\n",
    " (100, 250): 0.2703969553958662,\n",
    " (100, 350): 0.29776815242467924,\n",
    " (1000, 11): 0.21763164046085368,\n",
    " (1000, 50): 0.22069437118027563,\n",
    " (1000, 125): 0.23746854866082315,\n",
    " (1000, 200): 0.22573256964428604,\n",
    " (1000, 250): 0.23435294423273242,\n",
    " (1000, 350): 0.25400878483123424,\n",
    " (3000, 11): 0.21708701575300682,\n",
    " (3000, 50): 0.21948953352799538,\n",
    " (3000, 125): 0.22872920667907815,\n",
    " (3000, 200): 0.2225562088940296,\n",
    " (3000, 250): 0.2264492982777717,\n",
    " (3000, 350): 0.24119754914558456,\n",
    " (5000, 11): 0.21686743840521164,\n",
    " (5000, 50): 0.21898640741750486,\n",
    " (5000, 125): 0.22568012060609888,\n",
    " (5000, 200): 0.22240374315178094,\n",
    " (5000, 250): 0.2248758424106235,\n",
    " (5000, 350): 0.23697964201516844,\n",
    " (10000, 11): 0.21669252019829163,\n",
    " (10000, 50): 0.21852854901945928,\n",
    " (10000, 125): 0.2232050513633187,\n",
    " (10000, 200): 0.22266263741956352,\n",
    " (10000, 250): 0.2246121264495324,\n",
    " (10000, 350): 0.2330335124678897}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11) 0.2188\n",
      "(10, 50) 0.2291\n",
      "(10, 125) 0.312\n",
      "(10, 200) 0.3826\n",
      "(10, 250) 0.3305\n",
      "(10, 350) 0.3706\n",
      "(100, 11) 0.2185\n",
      "(100, 50) 0.2256\n",
      "(100, 125) 0.2666\n",
      "(100, 200) 0.2641\n",
      "(100, 250) 0.2704\n",
      "(100, 350) 0.2978\n",
      "(1000, 11) 0.2176\n",
      "(1000, 50) 0.2207\n",
      "(1000, 125) 0.2375\n",
      "(1000, 200) 0.2257\n",
      "(1000, 250) 0.2344\n",
      "(1000, 350) 0.254\n",
      "(3000, 11) 0.2171\n",
      "(3000, 50) 0.2195\n",
      "(3000, 125) 0.2287\n",
      "(3000, 200) 0.2226\n",
      "(3000, 250) 0.2264\n",
      "(3000, 350) 0.2412\n",
      "(5000, 11) 0.2169\n",
      "(5000, 50) 0.219\n",
      "(5000, 125) 0.2257\n",
      "(5000, 200) 0.2224\n",
      "(5000, 250) 0.2249\n",
      "(5000, 350) 0.237\n",
      "(10000, 11) 0.2167\n",
      "(10000, 50) 0.2185\n",
      "(10000, 125) 0.2232\n",
      "(10000, 200) 0.2227\n",
      "(10000, 250) 0.2246\n",
      "(10000, 350) 0.233\n"
     ]
    }
   ],
   "source": [
    "for thing in table_text:\n",
    "    print(thing, round(table_text[thing], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(cv_result, key=cv_result.get) #run this if you've run the cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter combo with lowest MRE in cv: nu=10000, W=11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.23680006074868834\n",
      "MRE from analyst estimates: 0.11550951150632237\n",
      "CPU times: user 17min 6s, sys: 208 ms, total: 17min 6s\n",
      "Wall time: 17min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "    \n",
    "    params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    y_pred=my_CorrelNowcast(**params)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.2368778361217034\n",
      "MRE from analyst estimates: 0.11550951150632237\n",
      "CPU times: user 1h 49min, sys: 200 ms, total: 1h 49min\n",
      "Wall time: 1h 49min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "    \n",
    "    params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    y_pred=my_CorrelNowcast(**params)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "b = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.23677090315990598\n",
      "MRE from analyst estimates: 0.11550951150632237\n",
      "CPU times: user 25min 53s, sys: 1.14 s, total: 25min 54s\n",
      "Wall time: 25min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "    \n",
    "    params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    y_pred=my_CorrelNowcast(**params)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.23672570355170766\n",
      "MRE from analyst estimates: 0.11550951150632237\n",
      "CPU times: user 17min 30s, sys: 204 ms, total: 17min 30s\n",
      "Wall time: 17min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "    \n",
    "    params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    y_pred=my_CorrelNowcast(**params)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.2442538560345735\n",
      "MRE from analyst estimates: 0.11550951150632237\n",
      "CPU times: user 1h 8min 57s, sys: 54.2 s, total: 1h 9min 51s\n",
      "Wall time: 17min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "    \n",
    "    params = {\n",
    "            'start_date': start_date, \n",
    "            'end_date': end_date, \n",
    "            'Info': Earnings_info, \n",
    "            'X_all': X, \n",
    "            'y_all': y_extra_info, \n",
    "            's': ticker, \n",
    "            'W': b,\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    y_pred=my_CorrelNowcast(**params)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRE from model actually higher then MRE from analyst estimates. This does not support the paper's claim."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

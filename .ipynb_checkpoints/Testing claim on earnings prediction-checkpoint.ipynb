{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('raw_data_bbg.xlsx',\n",
    "                 sheet_name='px_data',\n",
    "                header=0)\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "px=df.dropna(axis=1) #drop stocks without full data, 88 stocks remain\n",
    "px=px.set_index('Date')\n",
    "#px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL UW Equity', 'ABT UN Equity', 'ACN UN Equity', 'ADBE UW Equity',\n",
       "       'AIG UN Equity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list=px.columns\n",
    "stock_list[:5] #show first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be part of the feature space\n",
    "ma11=px.rolling(11).mean() \n",
    "ma50=px.rolling(50).mean()\n",
    "ma200=px.rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_excel('raw_data_bbg.xlsx',sheet_name='earn_data',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "earn_dates=df2.iloc[:, range(2,807,8) ]\n",
    "earn_dates.columns=df.columns[1:]\n",
    "#earn_dates  #holds the earnings announcement dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS=df2.iloc[:, range(5,807,8) ]\n",
    "EPS.columns=df.columns[1:]\n",
    "#EPS   #holds the 'comparable' EPS, i.e. not basic EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_EPS=df2.iloc[:, range(6,807,8) ]\n",
    "est_EPS.columns=df.columns[1:]\n",
    "#est_EPS   #holds the forecast consensus for the comparable EPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of CorrelNowcast algorithm from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "def my_CorrelNowcast(s, W, nu, X_all, y_all, Info,start_date, end_date ): \n",
    "    # s for bbg ticker, W for window size, nu for regularization param\n",
    "    # output inclusive of end date\n",
    "    \n",
    "    begin= np.where(X_all.index==start_date)[0][0] #get integer index corresponding to date\n",
    "    end= np.where(X_all.index==end_date)[0][0] \n",
    "\n",
    "    Ew_X=X_all.iloc[begin-W:begin,:] \n",
    "    Ew_y=y_all.iloc[begin-W:begin,0].to_numpy() #0 for the EPS column\n",
    "\n",
    "    fit=Ridge(alpha=nu).fit(Ew_X, Ew_y) #initialize\n",
    "\n",
    "    P=None\n",
    "    Q=None\n",
    "    output=np.zeros(end-begin+1)\n",
    "    for t in range(begin, end+1):\n",
    "\n",
    "        P= pd.DataFrame([X_all.iloc[t,:].to_numpy()]) \\\n",
    "            if P is None else P.append(pd.DataFrame([X_all.iloc[t,:].to_numpy()]))\n",
    "\n",
    "        if Q is None:\n",
    "            Q=list(fit.predict(X_all.iloc[t,:].to_numpy().reshape(1,-1)))\n",
    "        else:\n",
    "            Q.append(fit.predict(X_all.iloc[t,:].to_numpy().reshape(1,-1)))\n",
    "        \n",
    "        output[t-begin]=np.mean(Q)\n",
    "\n",
    "        if X_all.index[t] in Info.index: #if we are at an earnings announcement date\n",
    "            P.columns=Ew_X.columns #needed for correct appending\n",
    "            Ew_X=Ew_X.append(P) #works as the for loop in the paper\n",
    "            Ew_y=np.concatenate([Ew_y, [Info.loc[X_all.index[t], 'EPS']]*len(Q)])\n",
    "            P=None\n",
    "            Q=None\n",
    "            \n",
    "            if Ew_X.shape[0]>W:\n",
    "                Ew_X=Ew_X.iloc[-W:,:] #keep only W rows\n",
    "                Ew_y=Ew_y[-W:]\n",
    "            \n",
    "            fit=Ridge(alpha=nu).fit(Ew_X, Ew_y) #retrain\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation for nu and W (this code takes 6 hrs to run, results saved as text below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "nu=np.array([10, 100, 1000, 3000, 5000, 10000])\n",
    "W=np.array([11, 50, 125, 200, 250, 350]) #not doing 500 and 700\n",
    "cv_result=dict()\n",
    "\n",
    "for a in nu:\n",
    "    for b in W:\n",
    "        print('Now in loop: nu={:d}, W={:d}...'.format(a,b), end='')\n",
    "        MRE=np.zeros(len(stock_list))\n",
    "        for i, ticker in enumerate(stock_list):\n",
    "            print(i,end='') #visualize progress\n",
    "            cor11=px[ticker].rolling(11).corr(px)\n",
    "            cor50=px[ticker].rolling(50).corr(px)\n",
    "            cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "            temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "            temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "            X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "            X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "            Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                                  'EPS':EPS[ticker].dropna(),\n",
    "                                  'est_EPS':est_EPS[ticker].dropna()})\n",
    "            Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "            #X and y_extra_info shall hv same no. of rows\n",
    "            y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "            y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                                #remaining at the end since earnings not out yet. We\n",
    "                                                #won't be using those rows\n",
    "            #cross validation period\n",
    "            start_date='2013-02-08'\n",
    "            end_date='2015-02-09'\n",
    "\n",
    "            y_pred=my_CorrelNowcast(ticker, b, a, X, y_extra_info, Earnings_info,start_date,end_date)\n",
    "            MRE[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "            cv_result[(a,b)]=np.mean(MRE)\n",
    "        print('')   \n",
    "            \n",
    "\n",
    "cv_result            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " cv_result saved as text here:{(10, 11): 0.2187638191270434,\n",
    " (10, 50): 0.22906451942601178,\n",
    " (10, 125): 0.31202466937432827,\n",
    " (10, 200): 0.3825881964232682,\n",
    " (10, 250): 0.33047717422058687,\n",
    " (10, 350): 0.3705547594743095,\n",
    " (100, 11): 0.21851150849725237,\n",
    " (100, 50): 0.22558408007391287,\n",
    " (100, 125): 0.26659903572682564,\n",
    " (100, 200): 0.2640797603053457,\n",
    " (100, 250): 0.2703969553958662,\n",
    " (100, 350): 0.29776815242467924,\n",
    " (1000, 11): 0.21763164046085368,\n",
    " (1000, 50): 0.22069437118027563,\n",
    " (1000, 125): 0.23746854866082315,\n",
    " (1000, 200): 0.22573256964428604,\n",
    " (1000, 250): 0.23435294423273242,\n",
    " (1000, 350): 0.25400878483123424,\n",
    " (3000, 11): 0.21708701575300682,\n",
    " (3000, 50): 0.21948953352799538,\n",
    " (3000, 125): 0.22872920667907815,\n",
    " (3000, 200): 0.2225562088940296,\n",
    " (3000, 250): 0.2264492982777717,\n",
    " (3000, 350): 0.24119754914558456,\n",
    " (5000, 11): 0.21686743840521164,\n",
    " (5000, 50): 0.21898640741750486,\n",
    " (5000, 125): 0.22568012060609888,\n",
    " (5000, 200): 0.22240374315178094,\n",
    " (5000, 250): 0.2248758424106235,\n",
    " (5000, 350): 0.23697964201516844,\n",
    " (10000, 11): 0.21669252019829163,\n",
    " (10000, 50): 0.21852854901945928,\n",
    " (10000, 125): 0.2232050513633187,\n",
    " (10000, 200): 0.22266263741956352,\n",
    " (10000, 250): 0.2246121264495324,\n",
    " (10000, 350): 0.2330335124678897}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(cv_result, key=cv_result.get) #run this if you've run the cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter combo with lowest MRE in cv: nu=10000, W=11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index running...\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 \n",
      "Test period: 2015-03-09 to 2019-03-11\n",
      "MRE from model: 0.23691950516088855\n",
      "MRE from analyst estimates: 0.11550951150632237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error # need sklearn 0.24\n",
    "\n",
    "MRE_model=np.zeros(len(stock_list))\n",
    "MRE_bbg_est=np.zeros(len(stock_list))\n",
    "print('Index running...')\n",
    "for i, ticker in enumerate(stock_list):\n",
    "    print(i,'',end='') #visualize progress\n",
    "    cor11=px[ticker].rolling(11).corr(px)\n",
    "    cor50=px[ticker].rolling(50).corr(px)\n",
    "    cor200=px[ticker].rolling(200).corr(px)\n",
    "\n",
    "    temp1=pd.merge(px,cor11*ma11, left_index=True, right_index=True, suffixes=['_px', '_11'])\n",
    "    temp2=pd.merge(temp1,cor50*ma50, left_index=True, right_index=True, suffixes=[None, None] )\n",
    "    X=pd.merge(temp2,cor200*ma200, left_index=True, right_index=True , suffixes=['_50', '_200'])\n",
    "    X=X.dropna() #some top rows have Nan due to rolling averge calculations\n",
    "\n",
    "    Earnings_info=pd.DataFrame({'Announcement_dt':earn_dates[ticker].dropna(),\n",
    "                          'EPS':EPS[ticker].dropna(),\n",
    "                          'est_EPS':est_EPS[ticker].dropna()})\n",
    "    Earnings_info=Earnings_info.set_index('Announcement_dt')\n",
    "\n",
    "    #X and y_extra_info shall hv same no. of rows\n",
    "    y_extra_info=pd.merge(pd.DataFrame(index=X.index),Earnings_info, left_index=True, right_index=True, how='left')\n",
    "    y_extra_info=y_extra_info.fillna(method='bfill') #fill NaN with next earnings data, there will be some Nan\n",
    "                                        #remaining at the end since earnings not out yet. We\n",
    "                                        #won't be using those rows\n",
    "    #test data period - 4years\n",
    "    start_date='2015-03-09' #start date at least 11 trading days after cv period\n",
    "    end_date='2019-03-11'\n",
    "\n",
    "    y_pred=my_CorrelNowcast(ticker, 11, 10000, X, y_extra_info, Earnings_info,start_date,end_date)\n",
    "    MRE_model[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'], y_pred)\n",
    "    MRE_bbg_est[i]=mean_absolute_percentage_error(y_extra_info.loc[start_date:end_date,'EPS'],\n",
    "                                                  y_extra_info.loc[start_date:end_date,'est_EPS'])\n",
    "    \n",
    "\n",
    "print('\\nTest period: 2015-03-09 to 2019-03-11')\n",
    "print('MRE from model:', np.mean(MRE_model))\n",
    "print('MRE from analyst estimates:', np.mean(MRE_bbg_est))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRE from model actually higher then MRE from analyst estimates. This does not support the paper's claim."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
